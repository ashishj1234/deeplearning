In this code:

We load the MNIST dataset, which contains images of handwritten digits (0-9).

We preprocess the dataset by normalizing the pixel values to the range [0, 1] and one-hot encoding the labels.

We create a simple neural network model with L2 regularization applied to the first dense layer.

The model is compiled with an optimizer, loss function, and metrics.

We train the model using the training data and evaluate its performance on the test data.

Please note that this is a simple example for demonstration purposes. In real-world scenarios, you may want to use more complex architectures and tune hyperparameters for better performance. Additionally, you can adjust the regularization strength (0.01 in this example) and other hyperparameters to fit your specific requirements.